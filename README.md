# AudioSphere Listener

**AudioSphere Listener** es un componente personalizado para Gradio (versi√≥n 5.x) que provee una visualizaci√≥n 3D en tiempo real de la forma de onda de audio mediante una esfera de part√≠culas. Permite integraci√≥n plug-and-play con cualquier modelo ASR (reconocimiento autom√°tico de voz), ofrece detecci√≥n inteligente de silencio y es completamente responsive (desktop y mobile).  

---

## Tabla de Contenidos

1. [Visi√≥n General](#visi√≥n-general)  
2. [Caracter√≠sticas Principales](#caracter√≠sticas-principales)  
3. [Arquitectura y Estructura de Archivos](#arquitectura-y-estructura-de-archivos)  
4. [Tecnolog√≠as Utilizadas](#tecnolog√≠as-utilizadas)  
5. [Instalaci√≥n y Publicaci√≥n](#instalaci√≥n-y-publicaci√≥n)  
6. [Uso en Gradio (Ejemplos)](#uso-en-gradio-ejemplos)  
   1. [Configuraci√≥n B√°sica](#configuraci√≥n-b√°sica)  
   2. [Integraci√≥n con ASR (Whisper, Google STT, etc.)](#integraci√≥n-con-asr-whisper-google-stt-etc)  
   3. [Personalizaci√≥n Avanzada (Props y Callbacks)](#personalizaci√≥n-avanzada-props-y-callbacks)  
7. [Descripci√≥n T√©cnica Detallada](#descripci√≥n-t√©cnica-detallada)  
   1. [Inicializaci√≥n y Pipeline de Audio](#inicializaci√≥n-y-pipeline-de-audio)  
   2. [Motor 3D (Three.js) y Fallback (PixiJS)](#motor-3d-threejs-y-fallback-pixijs)  
   3. [Detecci√≥n de Silencio (RMS) y AGC/Noise Gate](#detecci√≥n-de-silencio-rms-y-agcnoise-gate)  
   4. [Sistema de Temas Din√°micos](#sistema-de-temas-din√°micos)  
   5. [Arquitectura de Plugins Visuales](#arquitectura-de-plugins-visuales)  
   6. [Accesibilidad y Atajos de Teclado](#accesibilidad-y-atajos-de-teclado)  
8. [Props y Curr√≠culum de API](#props-y-curr√≠culum-de-api)  
9. [Roadmap y Futuras Mejoras](#roadmap-y-futuras-mejoras)  
10. [Contacto y Soporte](#contacto-y-soporte)  

---

## Visi√≥n General

AudioSphere Listener redefine la experiencia de monitoreo de audio en aplicaciones Gradio al sustituir la forma de onda tradicional por una **esfera tridimensional de part√≠culas** que reacciona din√°micamente a la se√±al de audio entrante. Cada part√≠cula var√≠a su tama√±o, opacidad y color seg√∫n la energ√≠a de las bandas de frecuencia, mientras que toda la esfera rota suavemente en los ejes X, Y y Z para potenciar la sensaci√≥n de inmersi√≥n.  

El componente incluye:
- **Detecci√≥n inteligente de silencio** basada en RMS (Root Mean Square).  
- **Integraci√≥n plug-and-play con modelos ASR** (Whisper, Google Speech-to-Text, DeepSpeech, etc.) a trav√©s de callbacks en Python.  
- **Tematizaci√≥n din√°mica** (Dark/Light, esquemas personalizados) con transiciones suaves.  
- **Fallback autom√°tico** a PixiJS o Canvas 2D en navegadores sin WebGL o con bajo rendimiento.  
- **Responsive Design**: adaptativo a pantallas de escritorio, tablets y m√≥viles.  
- **Arquitectura de plugins visuales** que permite a√±adir nuevos efectos (ondas conc√©ntricas, humo, etc.) sin modificar el n√∫cleo.  
- **Accesibilidad (ARIA)** y **atajos de teclado** para que la interacci√≥n sea eficiente en cualquier contexto.  

---

## Caracter√≠sticas Principales

1. **Esfera de Part√≠culas 3D**  
   - Visualizaci√≥n en tiempo real de la forma de onda de audio mediante una malla de part√≠culas renderizada con Three.js.  
   - Cada part√≠cula se posiciona en la superficie de una esfera de ‚Äúradio virtual‚Äù y se anima seg√∫n datos de FFT (Fast Fourier Transform).  
   - Animaciones de expansi√≥n/contracci√≥n, variaci√≥n de color (fucsia ne√≥n, azul el√©ctrico, verde √°cido, etc.) y rotaci√≥n constante.  

2. **Detecci√≥n Autom√°tica de Silencio (RMS)**  
   - Procesamiento de fragmentos de audio (~250 ms) con `AudioContext.decodeAudioData`.  
   - C√°lculo de RMS:  
     \[
       RMS = \sqrt{\frac{1}{N} \sum_{i=1}^{N} x_i^2}
     \]  
     donde \(x_i\) son las muestras PCM normalizadas.  
   - Ventana deslizante (buffer de los √∫ltimos _n_ fragmentos) para evitar falsas detecciones.  
   - Si RMS < `silenceThreshold` durante `requiredSilentChunks` consecutivos (por defecto 8 √ó 250 ms = 2 s), se dispara el callback `on_silence`.  

3. **Integraci√≥n Plug-and-Play con Modelos ASR**  
   - El callback `on_audio_chunk(blob)` entrega cada fragmento (~250 ms) al backend Python.  
   - El desarrollador puede enviar ese `blob` a cualquier servicio ASR (Whisper local, Google Cloud STT, etc.) y recibir transcripciones parciales o finales.  
   - El callback `on_transcription(text)` se invoca para actualizar la interfaz con la transcripci√≥n recibida.  
   - Opcionalmente, el backend puede devolver un c√≥digo de idioma, enviado al callback para mostrar etiquetas de idioma (`ES ‚Äì Espa√±ol`, `EN ‚Äì English`).  

4. **Fallback a PixiJS o Canvas 2D**  
   - Si el navegador no soporta WebGL (o si se fuerza `fallback_to_pixi=True`), el componente utiliza PixiJS para emular la esfera de part√≠culas en 2D.  
   - En hardware limitado, se reduce din√°micamente el n√∫mero de part√≠culas para mantener 30 fps (adaptive particle count).  

5. **Responsive Design (Mobile y Desktop)**  
   - El `<canvas>` ocupa el 100 % del ancho del contenedor padre y escala su altura al 60 % del contenedor (o conforme a `canvas_width`/`canvas_height`).  
   - En pantallas peque√±as (< 400 px de ancho), el conteo de part√≠culas se reduce autom√°ticamente (por ejemplo, de 12 000 ‚Üí 6 000).  
   - La rotaci√≥n manual con arrastre del mouse se desactiva en dispositivos t√°ctiles para evitar interferencias con el scroll.  

6. **Tematizaci√≥n Din√°mica**  
   - El dropdown de temas (`show_theme_switcher=True`) permite alternar entre varios esquemas predefinidos (Cyberpunk, Ne√≥n Verde, P√∫rpura Gal√°ctico, etc.) y cargar themes personalizados desde `themes.json`.  
   - Las transiciones de color y fondo se animan en 0.3 s para no romper la experiencia.  
   - Soporta modo oscuro/ligero autom√°tico (`prefers-color-scheme`), y el atributo `data-theme="light"` en el contenedor ajusta botones, sliders y cajas de transcripci√≥n.  

7. **Arquitectura de Plugins Visuales**  
   - Se expone la interfaz TypeScript `VisualPlugin` que puede implementarse externamente.  
   - Los plugins se colocan en la carpeta `/plugins` y se cargan din√°micamente, sin necesidad de recompilar el componente.  
   - Ejemplos de plugins:  
     - `WaveFloorPlugin`: Piso ondulante bajo la esfera que vibra con la se√±al de baja frecuencia.  
     - `HaloGlowPlugin`: Halo luminoso que se expande y contrae detr√°s de la esfera.  
     - `LaserBeamsPlugin`: Rayos l√°ser 3D que se disparan en funci√≥n de picos de alta frecuencia.  

8. **Accesibilidad y Atajos de Teclado**  
   - Botones con `role="button"`, `aria-label="Iniciar grabaci√≥n"` y `aria-live="polite"` para notificaciones de estado.  
   - Teclas r√°pidas:  
     - **Barra espaciadora** ‚Üí Inicia/Detiene la grabaci√≥n.  
     - **Flecha arriba/abajo** ‚Üí Ajusta `silence_threshold` en incrementos de 0.005.  
   - Mensajes textuales breves (‚ÄúSilencio detectado: deteniendo escucha‚Äù) se emiten en la caja de transcripci√≥n con √©nfasis visual, facilitando a usuarios con p√©rdida auditiva.  

---

## Arquitectura y Estructura de Archivos

audio\_sphere\_listener/
‚îú‚îÄ‚îÄ component.ts                 # L√≥gica TypeScript principal (compilado a JS)
‚îú‚îÄ‚îÄ component.js                 # Versi√≥n compilada y minificada (para publicaci√≥n en Gradio CC)
‚îú‚îÄ‚îÄ component.css                # Estilos CSS puros para layout, responsividad y temas
‚îú‚îÄ‚îÄ component.toml               # Metadatos para publicar en Gradio CC
‚îú‚îÄ‚îÄ component.py                 # Wrapper Python para integraci√≥n con Gradio
‚îú‚îÄ‚îÄ themes.json                  # Esquemas de color (temas) cargados din√°micamente
‚îú‚îÄ‚îÄ plugins/                     # Carpeta para plugins de visualizaci√≥n (VisualPlugin)
‚îÇ   ‚îú‚îÄ‚îÄ WaveFloorPlugin.ts       # Ejemplo de plugin: piso ondulante
‚îÇ   ‚îú‚îÄ‚îÄ HaloGlowPlugin.ts        # Ejemplo de plugin: halo luminoso
‚îÇ   ‚îî‚îÄ‚îÄ LaserBeamsPlugin.ts      # Ejemplo de plugin: rayos l√°ser 3D
‚îî‚îÄ‚îÄ README.md                    # Este documento

````

- **component.ts / component.js**: contiene toda la l√≥gica de inicializaci√≥n, renderizado (Three.js o PixiJS), detecci√≥n de silencio, callbacks JS ‚Üî Python, tematizaci√≥n y carga de plugins.  
- **component.css**: define estilos globales (contenedor, canvas, botones, sliders, dropdowns, caja de transcripci√≥n), media queries para responsive y reglas para modo claro/oscuro.  
- **component.toml**: metadatos para la publicaci√≥n en Gradio CC (nombre, versi√≥n, descripci√≥n, autor, licencia).  
- **component.py**: clase `AudioSphereListener` en Python que extiende `gradio.components.Component`, inyecta scripts/CSS, expone props y callbacks para el desarrollador en `app.py`.  
- **themes.json**: archivo JSON que lista temas predefinidos; puede modificarse o ampliarse sin recompilar.  
- **plugins/**: directorio dedicado a plugins visuales que implementan la interfaz `VisualPlugin`. Al arrancar, el componente detecta archivos `.ts` o `.js` en `/plugins` y los inicializa autom√°ticamente.  

````
---

## Tecnolog√≠as Utilizadas

- **Gradio 5.x**   
  Framework para crear interfaces web interactivas en Python. `AudioSphereListener` se publica como componente personalizado y se usa directamente en un `gr.Blocks()`.

- **TypeScript / JavaScript**  
  - **Three.js** v0.128.0 (o superior)  
    Motor 3D WebGL para renderizar la esfera de part√≠culas en alta calidad.  
  - **PixiJS** v6.5.8  
    Fallback 2D en caso de que WebGL no est√© disponible o en hardware limitado.  
  - **Web Audio API**  
    - `navigator.mediaDevices.getUserMedia` ‚Üí captura del micr√≥fono.  
    - `AudioContext`, `AnalyserNode` ‚Üí procesamiento de se√±al en tiempo real (FFT y datos de dominio de tiempo).  
    - `MediaRecorder` ‚Üí fragmentaci√≥n de audio en `Blob`s de ~250 ms.  
  - **AudioWorklet (opcional)**  
    Para implementar Noise Gate y Control Autom√°tico de Ganancia (AGC) en el frontend, de modo que el audio enviado al ASR tenga mejor calidad.

- **CSS Puro**  
  - **Responsive Design**: media queries, flexbox, medidas relativas (%, rem).  
  - **Tematizaci√≥n Din√°mica**: variables CSS o cambios en `data-theme` para aplicar esquemas claro/oscuro y otros temas.  
  - **Accesibilidad**: roles ARIA, estilos de foco, alto contraste en botones y textos.

- **Python**  
  - **Wrapper de Componente** (`component.py`) extiende `gradio.components.Component`, inyecta HTML, CSS y JS necesarios al cargar la p√°gina.  
  - **Callbacks ASR**: permite usar modelos locales (Whisper) o externos (Google Cloud, AWS Transcribe, Azure Speech) para transcripci√≥n en tiempo real.

- **JSON**  
  - **themes.json**: define esquemas de color para tematizaci√≥n din√°mica sin recompilaci√≥n.  
  - Plugins visuales (`VisualPlugin`) pueden exponer su propia configuraci√≥n en JSON, si es necesario.

- **Herramientas Adicionales**  
  - **Rollup / Webpack / esbuild** (o similar) para compilar `component.ts` a `component.js`, optimizaci√≥n y minificaci√≥n.  
  - **tsconfig.json** y **package.json** (no incluidos en esta carpeta) para gestionar dependencias y compilaci√≥n de TypeScript.  

---

## Instalaci√≥n y Publicaci√≥n

Para que otros desarrolladores puedan instalar y usar **AudioSphere Listener** en sus proyectos Gradio, siga estos pasos:

1. **Clonar o descargar el repositorio**  
   ```bash
   git clone https://github.com/AitriaAI/AudioSphere-Listener.git
   cd audio_sphere_listener

2. **Instalar dependencias frontend (Solo si desea compilar localmente)**

   ```bash
   npm install three pixi.js typescript
   ```

   * Configure `tsconfig.json` seg√∫n convenga (target ES6, m√≥dulo ESNext).
   * Compilar TypeScript:

     ```bash
     npx tsc
     ```
   * Esto generar√° `component.js` a partir de `component.ts`.

3. **Verificar que est√©n presentes**

   * `component.js` (minificado y listo para producci√≥n).
   * `component.css`
   * `component.toml`
   * `component.py`
   * `themes.json`
   * Carpeta `plugins/` (con plugins de ejemplo).

4. **Publicar en Gradio CC**

   ```bash
   cd audio_sphere_listener
   gradio cc publish .
   ```

   * Esto publicar√° el componente en el registro de Gradio CC.
   * Una vez publicado, recibir√° un identificador, por ejemplo:

     ```
     audio_sphere_listener@0.1.0
     ```
   * Tome nota de este identificador para que otros puedan instalarlo.

5. **Instalaci√≥n en otro proyecto Gradio**
   En el proyecto donde desea usarlo, ejecute:

   ```bash
   gradio cc install audio_sphere_listener@0.1.0
   ```

   * Esto descargar√° `component.py`, `component.js`, `component.css` y dem√°s archivos necesarios.

6. **Verificaci√≥n de Archivos Instalados**

   * En la carpeta de componentes de Gradio (por defecto `~/.gradio/cc_components/audio_sphere_listener@0.1.0/`), debe ver:

     ```
     component.py
     component.js
     component.css
     component.toml
     themes.json
     plugins/
     ```

---

## Uso en Gradio (Ejemplos)

A continuaci√≥n se muestran varios escenarios de implementaci√≥n en un archivo `app.py` de Gradio. Se asume que ya se instal√≥ el componente mediante `gradio cc install audio_sphere_listener@0.1.0`.

### Configuraci√≥n B√°sica

```python
import gradio as gr
from audio_sphere_listener import AudioSphereListener

def on_start():
    print("üîä  Grabaci√≥n iniciada.")
    return "Grabando..."

def on_audio_chunk(blob):
    # Este callback recibe cada fragmento (~250 ms) como 'blob'.
    # Puede procesarlo o enviarlo a un ASR remoto/local.
    print("üì¶  Nuevo chunk de audio recibido.")
    return None  # No retornamos nada aqu√≠; la transcripci√≥n se maneja en on_transcription

def on_silence():
    print("ü§´  Silencio detectado. Deteniendo escucha.")
    return "Silencio detectado."

def on_stop():
    print("‚èπÔ∏è  Grabaci√≥n detenida.")
    return "Grabaci√≥n finalizada."

with gr.Blocks() as demo:
    gr.Markdown("## AudioSphere Listener: Ejemplo B√°sico")

    # Caja de texto para mostrar mensajes de estado (grabando, silencio, detenido)
    status_box = gr.Textbox(label="Estado", interactive=False)

    # Instanciar el componente con callbacks m√≠nimos
    audio_sphere = AudioSphereListener(
        on_start=lambda: status_box.update(on_start()),
        on_audio_chunk=on_audio_chunk,
        on_silence=lambda: status_box.update(on_silence()),
        on_stop=lambda: status_box.update(on_stop()),
        canvas_width=400,
        canvas_height=400,
        allow_sensitivity_adjustment=True,  # Muestra slider para ajustar umbral de silencio
    )

demo.launch()
```

**Explicaci√≥n**

* **`AudioSphereListener(...)`**: se crean instancias de los callbacks `on_start`, `on_audio_chunk`, `on_silence` y `on_stop`.
* **`status_box.update(...)`**: se usa para actualizar din√°micamente la caja de estado.
* `allow_sensitivity_adjustment=True` habilita el slider para ajustar en tiempo real el umbral de silencio (`silence_threshold`).

---

### Integraci√≥n con ASR (Whisper, Google STT, etc.)

```python
import gradio as gr
from audio_sphere_listener import AudioSphereListener

# Ejemplo con Whisper local
import whisper
model = whisper.load_model("base")

LANGUAGE_LABELS = {
    "es": "ES ‚Äì Espa√±ol",
    "en": "EN ‚Äì English",
    "fr": "FR ‚Äì Fran√ßais",
    # ...
}

def transcribe_blob(blob):
    """
    - Decodifica el blob (~250 ms) con Whisper.
    - Retorna la transcripci√≥n parcial y el idioma detectado.
    """
    result = model.transcribe(blob, language=None, task="transcribe")
    text = result["text"]
    lang = result.get("language", "es")
    return text, LANGUAGE_LABELS.get(lang, lang.upper())

def on_audio_chunk(blob):
    # Llamada al ASR en cada fragmento
    partial_text, language_label = transcribe_blob(blob)
    return partial_text, language_label

with gr.Blocks() as demo:
    gr.Markdown("## AudioSphere Listener + Whisper ASR")

    transcription_box = gr.Textbox(label="Transcripci√≥n en Vivo", interactive=False)
    language_label = gr.Label(label="Idioma Detectado")

    audio_sphere = AudioSphereListener(
        on_audio_chunk=lambda b: (
            transcription_box.update(transcribe_blob(b)[0]),
            language_label.update(transcribe_blob(b)[1])
        ),
        on_start=lambda: print("Grabaci√≥n iniciada..."),
        on_silence=lambda: transcription_box.update("Silencio detectado"),
        on_stop=lambda: transcription_box.update("Transcripci√≥n completada"),
        detect_language=True,              # El componente sabe que se muestra idioma
        allow_sensitivity_adjustment=True,
        show_theme_switcher=True,
        canvas_width=500,
        canvas_height=500
    )

demo.launch()
```

**Puntos clave**

* **`detect_language=True`** indica al componente que muestre el idioma detectado en la UI.
* El callback `on_audio_chunk` retorna una tupla `(texto, etiqueta_idioma)`, que se asigna a los componentes `transcription_box` y `language_label`.
* La transcripci√≥n se actualiza en tiempo real, fragmento a fragmento.

---

### Personalizaci√≥n Avanzada (Props y Callbacks)

```python
import gradio as gr
from audio_sphere_listener import AudioSphereListener

# Simulador de ASR remoto (pseudo-c√≥digo)
def asr_remote_service(audio_blob):
    # Ejemplo: enviar por HTTP a un endpoint de transcripci√≥n
    import requests
    files = {"file": ("chunk.webm", audio_blob, "audio/webm")}
    resp = requests.post("https://api-mi-asr.com/transcribe", files=files)
    data = resp.json()
    return data["text"], data.get("language", "en")

def on_start():
    # Se ejecuta cuando el usuario presiona ‚Äúüé§ Comenzar‚Äù
    return "‚ñ∂Ô∏è  Grabando..."

def on_silence():
    # Se ejecuta al detectar silencio (2 s por debajo del umbral)
    return "‚è∏Ô∏è  Silencio detectado"

def on_stop():
    # Se ejecuta al detener manual o por silencio
    return "‚èπÔ∏è  Grabaci√≥n detenida"

with gr.Blocks() as demo:
    gr.Markdown("## AudioSphere Listener: Personalizaci√≥n Completa")

    transcription_box = gr.Textbox(label="Transcripci√≥n (en Vivo)", interactive=False)
    language_label = gr.Label(label="Idioma Detectado")

    audio_sphere = AudioSphereListener(
        on_start=lambda: transcription_box.update(on_start()),
        on_audio_chunk=lambda b: transcription_box.update(asr_remote_service(b)[0]),
        on_transcription=lambda txt: transcription_box.update(txt),
        on_silence=lambda: transcription_box.update(on_silence()),
        on_stop=lambda: transcription_box.update(on_stop()),

        canvas_width=600,
        canvas_height=400,

        silence_threshold=0.015,       # Umbral de RMS m√°s estricto
        required_silent_chunks=6,      # 6 * 250ms = 1.5s para silencio
        particle_count=15000,          # Mayor detalle de part√≠culas
        particle_size_range=(0.015, 0.07),
        color_theme={
            "background_gradient": ["#001F00", "#003300"],
            "particle_colors": ["#00FF00", "#AAFF00"],
            "rim_color": "#55FF55"
        },
        detect_language=True,
        allow_sensitivity_adjustment=True,
        fallback_to_pixi=False,
        show_theme_switcher=True
    )

demo.launch()
```

**Aspectos de esta configuraci√≥n**

* Se modifica el `silence_threshold` y `required_silent_chunks` para detectar silencio m√°s r√°pidamente.
* Se aumenta `particle_count` a 15 000 para una esfera m√°s detallada, y se establecen rangos de tama√±o m√°s amplios (`0.015` ‚Äì `0.07`).
* `color_theme` define un esquema propio (fondo verde oscuro y part√≠culas verde ne√≥n).
* Los callbacks `on_start`, `on_audio_chunk`, `on_silence` y `on_stop` actualizan la caja de transcripci√≥n con mensajes espec√≠ficos.

---

## Descripci√≥n T√©cnica Detallada

### Inicializaci√≥n y Pipeline de Audio

1. **Captura de Micr√≥fono**

   * Se llama a

     ```ts
     navigator.mediaDevices.getUserMedia({ audio: true });
     ```

     solicitando permiso al usuario.
   * Si el permiso es rechazado, se notifica en consola y el componente permanece inactivo.

2. **Creaci√≥n de `AudioContext` y `AnalyserNode`**

   * `AudioContext` es la instancia principal:

     ```ts
     this.audioCtx = new AudioContext();
     const source = this.audioCtx.createMediaStreamSource(this.mediaStream);
     this.analyser = this.audioCtx.createAnalyser();
     this.analyser.fftSize = 2048;
     source.connect(this.analyser);
     ```
   * `AnalyserNode` proporciona dos salidas:

     * `getByteTimeDomainData(Uint8Array)`: datos de forma de onda (0‚Äì255).
     * `getByteFrequencyData(Uint8Array)`: datos de frecuencia (FFT, 0‚Äì255 por banda).

3. **Fragmentaci√≥n de Audio con `MediaRecorder`**

   * Se inicializa:

     ```ts
     this.recorder = new MediaRecorder(this.mediaStream, { mimeType: "audio/webm" });
     this.recorder.ondataavailable = (e: BlobEvent) => { ‚Ä¶ };
     this.recorder.start(250);
     ```
   * Cada 250 ms, `ondataavailable` recibe un `Blob` que contiene aproximadamente 250 ms de audio comprimido en `audio/webm`.
   * Dentro de este callback se desencadenan dos acciones principales:

     1. **Env√≠o al ASR**: si `on_audio_chunk` est√° definido, se invoca con el `Blob`.
     2. **C√°lculo de RMS**:

        * El `Blob` se lee como `ArrayBuffer` con `FileReader`.
        * `AudioContext.decodeAudioData(arrayBuffer)` ‚Üí `AudioBuffer a partir de datos PCM float32`.
        * Se extraen muestras: `audioBuffer.getChannelData(0)` ‚Üí `Float32Array`.
        * Se calcula RMS:

          ```ts
          let sumSquares = 0;
          for (let i = 0; i < pcmData.length; i++) {
            sumSquares += pcmData[i] * pcmData[i];
          }
          const rms = Math.sqrt(sumSquares / pcmData.length);
          ```
        * Se agrega `rms` al `this.rmsHistory` (capacidad = `requiredSilentChunks`).
        * Si todos los valores en `rmsHistory` est√°n por debajo de `silenceThreshold`, se invoca `triggerSilence()`.

4. **Detecci√≥n de Silencio y AGC/Noise Gate**

   * **RMS** en cada fragmento mide la energ√≠a global de la se√±al.
   * **Ventana deslizante** (√∫ltimos *n* fragmentos); si *n* valores consecutivos < `silenceThreshold`, se considera silencio.
   * **Noise Gate y AGC (opcional, AudioWorklet)**:

     * Antes de conectar el `AnalyserNode`, se inserta un `AudioWorkletNode` personalizado (`noise-gate-processor.js`), que filtra autom√°ticamente sonidos por debajo de cierto umbral y aplica ganancia autom√°tica para normalizar.
     * Este m√≥dulo mejora la calidad de audio enviado al ASR y reduce falsas detecciones de silencio.

---

### Motor 3D (Three.js) y Fallback (PixiJS)

#### Three.js

1. **Inicializaci√≥n**

   * Se crea:

     ```ts
     this.threeRenderer = new THREE.WebGLRenderer({
       canvas: this.canvas,
       antialias: true,
       alpha: true
     });
     this.threeRenderer.setPixelRatio(window.devicePixelRatio);
     this.threeRenderer.setSize(width, height);
     ```
   * **Escena**: `new THREE.Scene()`
   * **C√°mara**: `new THREE.PerspectiveCamera(45, width/height, 0.1, 1000)` posicionada en `(0, 0, 5)`.
   * **Luces**:

     * `AmbientLight(0xffffff, 0.5)`
     * `DirectionalLight(0xffffff, 0.7)` ubicado en `(5, 5, 5)`.
   * **Grupo de part√≠culas**: `this.sphereGroup = new THREE.Group(); this.threeScene.add(this.sphereGroup);`

2. **Geometr√≠a y Material de Part√≠culas**

   * **BufferGeometry** con atributos `position` (Float32Array √ó 3 √ó *N*) y `color` (Float32Array √ó 3 √ó *N*).
   * Distribuci√≥n de puntos en esfera (algoritmo de esfera de Fibonacci):

     ```ts
     const phi = Math.acos(1 - 2 * (i + 0.5) / particleCount);
     const theta = Math.PI * (1 + Math.sqrt(5)) * (i + 0.5);
     const x = Math.sin(phi) * Math.cos(theta);
     const y = Math.sin(phi) * Math.sin(theta);
     const z = Math.cos(phi);
     positions[3*i] = x;
     positions[3*i+1] = y;
     positions[3*i+2] = z;
     ```
   * **Vertex Colors**: interpolaci√≥n lineal entre `colorStart` y `colorEnd` para cada part√≠cula:

     ```ts
     colorStart.lerp(colorEnd, i / particleCount).toArray(colors, i * 3);
     ```
   * **PointsMaterial**:

     ```ts
     const material = new THREE.PointsMaterial({
       size: randomBetween(particleSizeRange[0], particleSizeRange[1]),
       vertexColors: true,
       transparent: true,
       opacity: 0.8
     });
     const particles = new THREE.Points(geometry, material);
     this.sphereGroup.add(particles);
     this.particleSystem = particles;
     ```

3. **Render Loop y Animaci√≥n**

   * Se crea una funci√≥n `animateThree()` que:

     1. Llama a `requestAnimationFrame(animateThree)`.
     2. Rota suavemente la esfera:

        ```ts
        this.sphereGroup.rotation.y += 0.002;
        this.sphereGroup.rotation.x += 0.001;
        ```
     3. Ajusta tama√±o del renderer si cambi√≥ el contenedor (responsive).
     4. Si `this.listening === true`:

        * Lee datos de frecuencia:

          ```ts
          const freqData = new Uint8Array(this.analyser.frequencyBinCount);
          this.analyser.getByteFrequencyData(freqData);
          const avgFreq = freqData.reduce((sum, v) => sum + v, 0) / freqData.length / 255;
          ```
        * Modifica `PointsMaterial.size = scaleFactor * maxSize` y `opacity = 0.5 + avgFreq √ó 0.5`.
     5. Llama a `this.threeRenderer.render(this.threeScene, this.threeCamera)`.

#### PixiJS (Fallback)

1. **Inicializaci√≥n**

   * Si WebGL no est√° disponible o `fallback_to_pixi=True`, se crea:

     ```ts
     this.pixiApp = new PIXI.Application({
       view: this.canvas,
       backgroundAlpha: 0,
       antialias: true,
       resolution: window.devicePixelRatio,
       width: width,
       height: height
     });
     this.pixiContainer = new PIXI.Container();
     this.pixiApp.stage.addChild(this.pixiContainer);
     ```

2. **Generaci√≥n de Part√≠culas en 2D**

   * Se crea un sprite circular para cada part√≠cula:

     ```ts
     const gfx = new PIXI.Graphics();
     const size = randomBetween(particleSizeRange[0] * 100, particleSizeRange[1] * 100);
     const colorHex = PIXI.utils.string2hex(randomBetweenColor(colorStart, colorEnd));
     gfx.beginFill(colorHex);
     gfx.drawCircle(0, 0, size);
     gfx.endFill();
     const texture = this.pixiApp.renderer.generateTexture(gfx);
     const sprite = new PIXI.Sprite(texture);
     // Posici√≥n aleatoria proyectada en 2D como si fuera superficie de esfera
     const angle = Math.random() * Math.PI * 2;
     const radius = Math.random() * Math.min(width, height) * 0.4;
     sprite.x = width/2 + radius * Math.cos(angle);
     sprite.y = height/2 + radius * Math.sin(angle);
     sprite.alpha = 0.8;
     this.pixiContainer.addChild(sprite);
     ```
   * Cada tick (`app.ticker.add(this.animatePixi.bind(this))`) rota el contenedor y, si `this.listening === true`, ajusta `sprite.scale.set(1 + avgFreq √ó 0.5)` y `sprite.alpha = 0.5 + avgFreq √ó 0.5`.

---

### Detecci√≥n de Silencio (RMS) y AGC/Noise Gate

1. **Buffer Deslizante de RMS**

   * `this.rmsHistory` almacena hasta `requiredSilentChunks` valores de RMS.
   * Cada vez que se recibe un fragmento de audio (Blob), se calcula RMS:

     ```ts
     function calculateRMS(buffer: Float32Array): number {
       let sumSquares = 0;
       for (let i = 0; i < buffer.length; i++) {
         sumSquares += buffer[i] * buffer[i];
       }
       return Math.sqrt(sumSquares / buffer.length);
     }
     ```
   * Se agrega el valor a `rmsHistory`; si su longitud supera `requiredSilentChunks`, se elimina el elemento m√°s antiguo.
   * Si `rmsHistory.length === requiredSilentChunks` y **todos** los valores < `silenceThreshold`, se invoca `triggerSilence()`.

2. **Noise Gate y AGC (AudioWorklet)**

   * Antes de conectar el `AnalyserNode`, opcionalmente se registra y utiliza un `AudioWorkletNode` que filtra ruidos por debajo de un umbral y aplica ganancia autom√°tica:

     ```ts
     await this.audioCtx.audioWorklet.addModule("noise-gate-processor.js");
     const noiseGateNode = new AudioWorkletNode(this.audioCtx, "noise-gate-processor", {
       processorOptions: { threshold: this.silenceThreshold }
     });
     source.connect(noiseGateNode).connect(this.analyser);
     ```
   * El procesador `noise-gate-processor.js` (implementado en Web Audio Worklet) analiza muestras en tiempo real y suprime audio cuando est√° por debajo de `threshold`, adem√°s de normalizar niveles altos.

---

### Sistema de Temas Din√°micos

1. **Archivo `themes.json`**
   Define esquemas de color para el fondo y part√≠culas.

   ```json
   {
     "cyberpunk": {
       "background_gradient": ["#1E1B2D", "#0F0C1B"],
       "particle_colors": ["#FF00FF", "#00FFFF"],
       "rim_color": "#FF0099"
     },
     "neon-green": {
       "background_gradient": ["#001F00", "#003300"],
       "particle_colors": ["#00FF00", "#AAFF00"],
       "rim_color": "#55FF55"
     },
     "galactic-purple": {
       "background_gradient": ["#2B0035", "#1A001D"],
       "particle_colors": ["#AA00FF", "#FF00AA"],
       "rim_color": "#D58AFF"
     }
   }
   ```

2. **Selector de Tema (Dropdown)**

   * Si `show_theme_switcher=True`, en `initControls()` se agrega un `<select>` con las claves de `themes.json` (Cyberpunk, Neon Green, Galactic Purple, etc.).
   * Al cambiar la selecci√≥n, `applyTheme(themeKey)` actualiza:

     * **Fondo** del contenedor:

       ```ts
       container.style.background = `linear-gradient(135deg, ${background_gradient[0]}, ${background_gradient[1]})`;
       ```
     * **Colores de Part√≠culas**: recalcula el atributo `color` de `BufferGeometry` en Three.js, o regenera texturas de PixiJS si corresponde.
   * Transici√≥n suave (0.3 s) mediante CSS (`transition: background 0.3s ease`).

---

### Arquitectura de Plugins Visuales

1. **Interfaz TypeScript `VisualPlugin`**

   ```ts
   export interface VisualPlugin {
     /** Nombre √∫nico del plugin */
     name: string;

     /**
      * Inicializa el plugin.
      * - `sceneOrContainer` : instancia de THREE.Scene o PIXI.Container
      * - `props` : configuraci√≥n del componente (AudioSphereListenerProps)
      */
     initialize(
       sceneOrContainer: THREE.Scene | PIXI.Container,
       props: AudioSphereListenerProps
     ): void;

     /**
      * Actualiza el plugin en cada frame de animaci√≥n.
      * - `timestamp` : tiempo actual (ms)
      * - `analyserData` : Uint8Array con datos de frecuencia (FFT)
      */
     update(timestamp: number, analyserData: Uint8Array): void;

     /** Limpia recursos y listeners cuando el componente se destruye. */
     dispose(): void;
   }
   ```

2. **Carga Din√°mica**

   * En el constructor de `AudioSphereListener`, despu√©s de inicializar Three.js/PixiJS, se recorre la carpeta `plugins/` y se importa cada m√≥dulo que cumpla con la interfaz `VisualPlugin`.
   * Cada plugin recibe la instancia de la escena (`Three.Scene` o `Pixi.Container`) y `props` para configurarse.
   * En cada iteraci√≥n del render loop (`animateThree` o `animatePixi`), se llama a `plugin.update(timestamp, analyserData)`.

3. **Ejemplo de Plugin (WaveFloorPlugin.ts)**

   ```ts
   import * as THREE from "three";
   import { VisualPlugin, AudioSphereListenerProps } from "../component";

   export default class WaveFloorPlugin implements VisualPlugin {
     name = "WaveFloorPlugin";
     private floorMesh?: THREE.Mesh;
     private analyser?: AnalyserNode;

     initialize(scene: THREE.Scene, props: AudioSphereListenerProps) {
       this.analyser = props.analyserNode; // Asumiendo que el plugin recibe referencia
       const geometry = new THREE.PlaneGeometry(5, 5, 64, 64);
       const material = new THREE.MeshPhongMaterial({
         color: 0x2222ff,
         side: THREE.DoubleSide,
         flatShading: true
       });
       this.floorMesh = new THREE.Mesh(geometry, material);
       this.floorMesh.rotation.x = -Math.PI / 2;
       this.floorMesh.position.y = -1;
       scene.add(this.floorMesh);
     }

     update(timestamp: number, freqData: Uint8Array) {
       if (!this.floorMesh || !this.analyser) return;
       this.analyser.getByteFrequencyData(freqData);
       const avgLowFreq = freqData.slice(0, freqData.length / 4).reduce((a, b) => a + b, 0) / (freqData.length / 4);
       const displacement = avgLowFreq / 255;
       const geometry = this.floorMesh.geometry as THREE.PlaneGeometry;
       for (let i = 0; i < geometry.attributes.position.count; i++) {
         const y = Math.sin(i + timestamp * 0.001) * displacement * 0.5;
         (geometry.attributes.position as THREE.BufferAttribute).setY(i, y);
       }
       (geometry.attributes.position as THREE.BufferAttribute).needsUpdate = true;
     }

     dispose() {
       if (this.floorMesh) {
         this.floorMesh.geometry.dispose();
         (this.floorMesh.material as THREE.Material).dispose();
         this.floorMesh.parent?.remove(this.floorMesh);
       }
     }
   }
   ```

   * Este plugin crea un ‚Äúsuelo‚Äù ondulante que vibra con la energ√≠a de las frecuencias bajas.
   * Se suscribe al `AnalyserNode` para extraer datos de frecuencia en `update()`.

---

### Accesibilidad y Atajos de Teclado

1. **Atributos ARIA**

   * Botones:

     ```html
     <button 
       role="button" 
       aria-label="Iniciar grabaci√≥n" 
       class="audio-sphere-btn start-btn">
       üé§ Comenzar
     </button>
     ```
   * Caja de transcripci√≥n:

     ```html
     <div 
       role="region" 
       aria-live="polite" 
       aria-label="Transcripci√≥n en vivo" 
       class="audio-sphere-transcription">
       <!-- Texto de transcripci√≥n -->
     </div>
     ```

2. **Atajos de Teclado**

   * Dentro del constructor de `AudioSphereListener`, se agrega un listener global:

     ```ts
     document.addEventListener("keydown", (event) => {
       if (event.code === "Space") {
         event.preventDefault();
         this.listening ? this.stopListening() : this.startListening();
       } else if (event.code === "ArrowUp") {
         this.silenceThreshold = Math.max(0, this.silenceThreshold - 0.005);
       } else if (event.code === "ArrowDown") {
         this.silenceThreshold += 0.005;
       }
     });
     ```
   * Se actualiza visualmente el slider de silencio cuando cambia via flechas.
   * Notificaciones de estado (‚ÄúSilencio detectado‚Äù, ‚ÄúGrabaci√≥n iniciada‚Äù) se emiten en la caja de transcripci√≥n con `aria-live="polite"` para lectores de pantalla.

---

## Props y Curr√≠culum de API

A continuaci√≥n se detalla cada prop que el desarrollador puede configurar al instanciar `AudioSphereListener` en Gradio:

| Prop                     | Tipo           | Descripci√≥n                                                                                                                                                              | Default        |
| ------------------------ | -------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------------- |
| `on_start`               | `callable`     | Callback en Python que se ejecuta cuando el usuario presiona ‚Äúüé§ Comenzar‚Äù. Retorna texto o None.                                                                        | `None`         |
| `on_audio_chunk`         | `callable`     | Callback que recibe cada `Blob` de audio (\~250 ms). Ideal para enviar al ASR.                                                                                           | `None`         |
| `on_silence`             | `callable`     | Callback que se dispara cuando se detecta silencio constante (RMS < `silence_threshold` por `required_silent_chunks`).                                                   | `None`         |
| `on_stop`                | `callable`     | Callback en Python que se invoca cuando la grabaci√≥n se detiene manualmente o por detecci√≥n de silencio.                                                                 | `None`         |
| `on_transcription`       | `callable`     | Callback que recibe transcripciones parciales o finales desde el backend ASR.                                                                                            | `None`         |
| `canvas_width`           | `int`          | Ancho m√≠nimo en p√≠xeles del `<canvas>`. El componente se escala responsivamente si el contenedor es mayor.                                                               | `300`          |
| `canvas_height`          | `int`          | Alto m√≠nimo en p√≠xeles del `<canvas>`. El componente se escala responsivamente seg√∫n altura disponible en el contenedor.                                                 | `300`          |
| `silence_threshold`      | `float`        | Nivel m√≠nimo de RMS (0‚Äì1) para considerar ‚Äúactividad de voz‚Äù. Si el RMS cae por debajo de este umbral en `required_silent_chunks` consecutivos, se dispara `on_silence`. | `0.01`         |
| `required_silent_chunks` | `int`          | Cantidad de fragmentos (cada uno de 250 ms) consecutivos con RMS < `silence_threshold` para disparar `on_silence`.                                                       | `8`            |
| `particle_count`         | `int`          | N√∫mero de part√≠culas que forman la esfera. A mayor n√∫mero, m√°s detalle, pero puede impactar el rendimiento.                                                              | `10000`        |
| `particle_size_range`    | `tuple[float]` | Rango `[minSize, maxSize]` (Three.js units o p√≠xeles en PixiJS) para definir el tama√±o inicial de cada part√≠cula.                                                        | `(0.02, 0.05)` |
| `color_theme`            | `dict`         | Esquema de color para fondo y part√≠culas. Estructura:                                                                                                                    |                |

````json
{
  "background_gradient": ["#1E1B2D", "#0F0C1B"],
  "particle_colors": ["#FF00FF", "#00FFFF"],
  "rim_color": "#FF0099"
}
````
                                                                                             | Esquema Cyberpunk por defecto |
| `detect_language`            | `bool`           | Si `true`, se espera que el backend ASR retorne un c√≥digo de idioma (ISO 639-1). Se muestra en la etiqueta `language_label`.                                              | `False`      |
| `allow_sensitivity_adjustment` | `bool`         | Si `true`, exhibe un slider para ajustar en tiempo real el `silence_threshold`.                                                                                            | `False`      |
| `fallback_to_pixi`           | `bool`           | Si `true`, fuerza el uso de PixiJS en lugar de Three.js (√∫til para navegadores sin WebGL o baja capacidad gr√°fica).                                                        | `False`      |
| `show_theme_switcher`        | `bool`           | Si `true`, habilita un dropdown para cambiar entre temas cargados desde `themes.json`.                                                                                    | `False`      |
| `elem_id`                    | `str`            | Identificador HTML √∫nico para el contenedor del componente. Si no se provee, se genera autom√°ticamente.                                                                    | Generado     |

---

## Roadmap y Futuras Mejoras

1. **Optimizaci√≥n mediante Web Workers**  
   - Externalizar el c√°lculo de RMS y FFT a un Web Worker, liberando el hilo principal para mantener 60 fps estables, aun en hardware de gama baja.

2. **Grabaci√≥n Completa y Exportaci√≥n**  
   - Funcionalidad para concatenar todos los fragments de `MediaRecorder` en un √∫nico `Blob` final y permitir la descarga en formatos `webm`, `ogg` o `mp3`.  
   - Prop `enable_record_download: bool` que, cuando se activa, muestra un bot√≥n ‚ÄúDescargar grabaci√≥n‚Äù.

3. **Soporte Multicanal (Est√©reo)**  
   - Adaptar el pipeline de audio para procesar y visualizar de forma separada los canales izquierdo y derecho, ya sea mediante dos esferas independientes o un dise√±o de doble anillo de part√≠culas.

4. **Visualizaci√≥n de Texto en 3D (Three.js TextGeometry)**  
   - Integrar el texto de transcripci√≥n como `TextGeometry` que orbita alrededor de la esfera, girando en sincron√≠a con la animaci√≥n principal y cambien la escala seg√∫n la claridad de la transcripci√≥n.

5. **M√≥dulo de Autenticaci√≥n y Colaboraci√≥n en Tiempo Real**  
   - Incorporar WebRTC (TURN/STUN) para permitir que m√∫ltiples usuarios compartan en tiempo real su esfera de visualizaci√≥n en conferencias remotas, cada quien con su propia instancia de AudioSphere.  
   - Prop `session_id: str` que identifica la sala colaborativa y sincroniza audio/visual a trav√©s de WebSockets.

---

## Contacto y Soporte

- **Repositorio Oficial**:  
  https://github.com/tu-usuario/audio_sphere_listener  

- **Documentaci√≥n Adicional y Ejemplos**:  
  - Carpeta `/examples/`: proyectos de muestra que muestran diferentes escenarios de uso.  
  - `/docs/`: gu√≠as detalladas para desarrollo de plugins y temas personalizados.

- **Preguntas y Reporte de Errores**:  
  - Cree un **Issue** en GitHub describiendo el problema con detalle (versi√≥n de navegador, logs de consola, sistema operativo).  
  - Para solicitudes de nuevas caracter√≠sticas, agregue un **Feature Request** describiendo el caso de uso y posibles soluciones.

- **Licencia**:  
  Apache 2.0 License. Puedes revisar el archivo [APACHE-2.0](https://www.apache.org/dev/) en el repositorio.

---

**AudioSphere Listener** est√° dise√±ado para elevar la experiencia de interacci√≥n por voz en aplicaciones Gradio. Su combinaci√≥n de renderizado 3D avanzado, detecci√≥n de silencio inteligente, integraci√≥n con ASR y arquitectura extensible lo convierte en la soluci√≥n ideal para cualquier proyecto que demand√© un feedback visual y auditivo de vanguardia.
